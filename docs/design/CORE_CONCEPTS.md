# AIOps-Intelligent-RCA v2.0: 神经符号化故障分诊引擎

> **Author:** qingshanyuluo
> **Status:** Production-Grade State of the Art
> **Core Philosophy:** "Deterministic Workflow, Probabilistic Inference" (确定性的流，概率性的脑)
> **Architecture Pattern:** Neuro-Symbolic AI (神经符号人工智能)

---

## 1. 序言：从“黑盒代理”到“白盒工厂”

在经历了 ReAct (Reasoning and Acting) 模式在运维领域的幻觉与不可控后，我们回归了第一性原理：**运维排障的本质不是探索（Exploration），而是验证（Verification）。**

当前市面上的 AIOps 方案依然沉迷于让 LLM 像人一样去使用工具（Tool-use），这忽略了一个致命的事实：**大模型严重缺乏运维领域的“过程思维链”训练数据。**

**本项目的核心破局点在于“去 Agent 化”：**
1.  **收敛入口：** 我们不再监听全网所有指标，而是锁死 **RPC Error** 这一“黄金咽喉”。经验证明，RPC 异常覆盖了 90% 的异常与 100% 的生产故障。
2.  **固化流程：** 放弃不确定的 ReAct 循环，采用 **分支型固定 SOP (Branching Fixed SOP)**。
3.  **LLM 降级：** LLM 不再是指挥官（Commander），而是流水线上的 **高智商质检员 (Node)**。它不负责决定“下一步做什么”，只负责在给定的步骤中“看懂非结构化数据”。

我们构建的不是一个会聊天的机器人，而是一座**由算法驱动传送带、由 LLM 负责精细加工的自动化分诊工厂**。

---

## 2. 核心架构：漏斗式分诊流水线 (The Triage Funnel)

我们将 RCA 过程重构为**高度收敛**的四阶段漏斗。所有故障必须经过这套严格的“安检”，确保每一步的输入都是经过高度结构化处理的。

### Stage 0: 全局嫌疑人识别与证据固定 (The Dossier)
*   **目标：** 在故障发生的瞬间，构建一个包含所有潜在关联方的“案发现场快照”，避免因只关注报错应用而遗漏“沉默的性能恶化者”。
*   **动作：**
    1.  **识别嫌疑人：** 通过监控实时 RPC 错误流和扫描全局服务性能指标，生成一份包含**报错池 (Error Pool)**和**异动池 (Anomaly Pool)**的完整嫌疑人名单。
    2.  **并发固定证据：** 对名单中的所有应用，并发抓取其排障所需的全量数据（指标、日志、告警、变更、线程 Dump 等）。
*   **输出：** 一个标准化的 **“故障档案 (Dossier)”**，作为整个后续分析流程的唯一、不可变的数据源。

### Stage 1: 全局共模熔断 (The Shield)
*   **目标：** 快速识别并熔断由基础设施或平台级故障引发的“告警风暴”，防止系统在无效的单点分析上空耗资源。
*   **动作：** 通过分析全局服务的错误率分布模式，判定故障是“平台型”（影响范围广，错误率分布平缓）还是“断崖型”（集中在少数应用）。
*   **决策：**
    *   **平台型故障：** 直接熔断，输出全局告警（如：网络专线抖动、云厂商故障），终止后续分析。
    *   **断崖型故障：** 将错误率最高的应用视为主要嫌疑人，放行至下一阶段。

### Stage 2: 加权拓扑挖掘与入口纠偏 (The Compass)
*   **目标：** 纠正一个常见的误区——报错节点不等于根因节点。此阶段旨在通过纯数学计算，定位到分布式链路中真正的“阻力点”。
*   **动作：**
    1.  **构建内存拓扑图：** 将批量错误 Trace 在内存中实时折叠成一个局部加权拓扑图。
    2.  **计算破坏力权重：** 对图中的每条“边”和每个“节点”计算其对链路的综合影响权重。
    3.  **强制校准入口：** 根据权重计算结果，**动态纠偏**分析入口，可能指向某个**交互/网络问题（边）**、某个**节点自身计算问题**或保持原有的**报错节点**。
*   **价值：** 此阶段确保了后续所有深度分析都聚焦在经过数据验证的、真正的瓶颈之上。

### Stage 3: 证据深化与现场重建 (The Investigator)
*   **目标：** 围绕 Stage 2 确定的核心嫌疑对象，进行多维度的深度证据勘探，并构建一张完整的“故障全景图”。
*   **动作：**
    1.  **日志趋势突变检测：** 自动发现异常激增的错误日志模式。
    2.  **异常指标监测：** 利用统计学算法毫秒级检测应用所有指标，给出异常指标列表，算法见[文档](/docs/design/timeseries-analysis.md)。
    3.  **变更、告警信息精简：** 提取原始数据核心数据，转化为Markdown格式，减少token消耗。
    4.  **递归式现场扩展 (Recursive Scene Expansion):**
        *   **核心逻辑:** 真正的根因可能不在最初的嫌疑人身上，而在其高流量的下游。
        *   **动作:** 系统会检查核心嫌疑人的高流量下游依赖，并**执行严密的“存在性验证”工作流**：
            1. **提取名单：** 从当前服务的错误日志或依赖拓扑中，提取出报错最多或QPS最高的下游应用服务名。
            2. **验证存在性：** 通过查询数据系统，验证这些下游服务在故障时间段内**是否存在其自身的“故障档案 (Dossier)”**。
            3. **分支决策：**
                *   **✅ 存在档案：** 证明该下游服务也是“第一现场”，系统会将其自动纳入“案发现场”，采集其全套证据，并可能**递归地对其启动一轮完整的分析流程**。
                *   **❌ 不存在档案：** 证明该下游服务自身运行平稳，是“被动受害者”。分析焦点将继续保持在当前服务或网络交互上。
    *   **输出:** 构建出一张经过下游验证、包含所有**主动异常节点**的**“故障全景图 (Incident Panorama)”**。

### Stage 4: 两阶段交叉审问与定责 (The Prosecutor)

**解决痛点：**
1.  **LLM 惰性：** Stage 3 输出的“故障全景图”信息量巨大，直接投喂会导致 LLM 忽略关键细节。
2.  **逻辑谬误：** LLM 倾向于将最显眼的症状（如 GC 升高）直接归因为根因，缺乏批判性思维。

为此，我们将最终的推理阶段重构为一个**强制性的、如同架构中“最终逻辑门（Gatekeeper）”的两阶段交叉审问 (Two-Phase Cross-Examination)** 

*   **动作：**
    1.  **Phase 1 - 强制循证与浅层结论提取：** 通过引导式 Prompt，强制 LLM 完整消化所有证据材料，并提炼出一个初步的、未经审视的故障猜想。
    2.  **Phase 2 - ** 反事实质询与深度归因 (Counterfactual Inquisition & Deep Attribution)**
        *   **目的：** 挑战浅层结论，通过一个**不可跳过的、程序化的逻辑压力测试**，逼近真相。
        *   **提示词策略：** 系统将 Phase 1 的浅层结论作为“靶子”，自动生成一系列基于 **SRE 第一性原理（见第3节）** 的“反事实假设”来质询 LLM。

*   **最终输出：** 一份经过交叉审问和逻辑验证的、高置信度的最终诊断报告。

---

## 3. 核心算法与原则

本项目的有效性根植于一系列为运维场景深度定制的算法和逻辑原则。

### 3.1 嫌疑人识别与故障定界算法
*   **带噪底的自适应 Z-Score (Adaptive Z-Score with Noise Floor):** 用于 Stage 0。此算法在传统 Z-Score 基础上增加了对稳定“噪声”的识别，能精准识别出那些“行为反常”（如耗时显著偏离自身历史基线）的服务，即使它们尚未报错。
*   **基于“错误率梯度”的故障定界算法 (Error Rate Gradient-based Fault Localization):** 用于 Stage 1。通过计算和比较归一化后服务错误率的**梯度（倍数差）**，快速区分是影响面广的“平台型”故障（梯度平缓），还是由单点爆发的“断崖型”故障（梯度陡峭）。


### 3.2 基于基线偏差的加权拓扑挖掘 (Baseline Deviation Weighted Mining)

* **核心逻辑更新**：用于 Stage 2。原有的绝对值阻力模型已被弃用，改为**“偏差增益模型”**。该算法不再单纯累加当前的耗时或错误数，而是计算当前指标相对于该节点**历史基线（Rolling Baseline）**的偏离程度。
* **解决痛点**：通过计算 （增量），有效规避了固定阈值带来的误判。
* *场景应对*：若前置节点 A 耗时从 10ms 激增至 2s（ 极大），导致后置节点 B 超时报错但自身耗时很短（ 极小）。算法将赋予节点 A 极高的权重，从而正确跳过报错点 B，定位到真正的延迟根因 A。


#### 修正后的权重公式

$$W_{edge} = \underbrace{SpanCount \times (AvgLat_{curr} - AvgLat_{base})}_{\text{计算耗时偏差 (Computation Deviation)}} + \underbrace{\sum(Gap_{curr} - Gap_{base})}_{\text{传输/GC偏差 (Transmission Deviation)}} + \underbrace{ErrorCount \times (AvgLat_{base} \times \beta)}_{\text{动态错误惩罚 (Dynamic Error Penalty)}}$$

#### 变量定义与逻辑闭合：

1. **计算耗时偏差 (Computation Deviation)**：
* ：直观反映了该节点比“平时”慢了多少。
* 若当前耗时小于基线，该项归零，避免奖励异常快的服务（可能是非预期短路）。
* 此项确保了耗时剧增的节点（即使未报错）获得最高权重。


2. **传输/GC/线程池排队偏差 (Transmission Deviation)**：
* $Gap = ClientDur - ServerDur$
* 计算网络传输或客户端 GC 导致的额外延迟增量。排除正常的网络 RTT 波动，仅关注异常增量。


3. **动态错误惩罚 (Dynamic Error Penalty)**：
* **逻辑变更**：移除了固定的  值（如 5000ms）。
* **新算法**：使用  作为单次错误的惩罚当量。
* ** (敏感度系数)**：通常设为 2~3。意味着“一次错误等同于该接口耗时变成了平时的 2~3 倍”。
* **效果**：对于本身就是长耗时的接口，错误的权重会自动放大；对于毫秒级微服务，错误的权重保持在低位。这保证了错误判定与接口本身的量级强相关，避免了短耗时服务的错误掩盖了长耗时服务的延迟问题。


### 3.3 核心逻辑：质疑显性症状

#### A. 概率独立性原则 (针对超时场景)
*   **现象:** MySQL, Redis, ES 等多个独立组件的客户端监控耗时同时变慢。
*   **直觉:** 三个组件都坏了。
*   **反事实:** “三个独立的、解耦的服务端组件同时发生物理故障的概率趋近于零。”
*   **结论:** 必然是**应用自身**（Caller）出现了 CPU 争抢、GC 停顿或线程池拥堵，导致客户端计时器变慢或无法及时处理返回。
*   **黄金口诀:** > **单独涨 = 组件问题；一起涨 = 自身问题。**
    > 这个简单的启发式规则，能瞬间将分析师从对多个下游的无效怀疑中解放出来，聚焦于调用方自身的资源瓶颈。

#### B. 资源受害者假设 (针对资源报警)
*   **现象:** 应用 CPU 达到 100%。
*   **反事实:** “如果没有代码 Bug 或流量突增，CPU 为什么会满？资源耗尽通常是‘果’而不是‘因’。”
*   **验证:**
    1.  **定性检查：** 是否存在下游服务响应变慢，或上游流量激增？下游的缓慢响应会导致上游线程池堆积，进而耗尽 CPU 和内存。
    2.  **定量核算：** 对于高 QPS 的下游依赖，必须进行冲击力计算。
        > **冲击力公式: `Impact = ΔLatency × QPS`**
        >
        > 例如，一个 QPS 为 2000 的下游服务，其 P99 延迟仅增加了 50ms，那么对上游造成的额外线程占用时间就高达 `0.05s * 2000/s = 100` 个并发线程。这个冲击是否足以压垮当前服务的线程池或 CPU？通过这种量化计算，可以将“猜测”变为“证明”。
*   **推论:** 如果下游变慢导致的冲击力足以解释当前的资源耗尽，那么 **CPU 飙升是结果（受害者），而非原因**。真正的根因在于下游。

#### **C. 幸存者偏差验证 (Survivor Bias Verification)**
*   **这是原博客未提及的全新维度，用于补充横向视角，防止“只见树木，不见森林”。**
*   **核心逻辑：** 仅仅分析“异常”的组件是不够的，还必须审视那些“正常”的组件，并提出关键问题。
*   **反问清单：**
    *   **“为什么同集群的其他节点没事？”** 如果只有单个 Pod 异常，而其他 Pod 正常，那么问题很可能出在该 Pod 特有的因素上（如代码发布批次、节点硬件问题、不均匀的流量负载），而非整个服务的设计缺陷或平台级问题。
    *   **“为什么其他依赖（在相同网络环境下）没有报错？”** 如果你怀疑是网络抖动，但只有对下游 A 的调用报错，而对同网络环境下的下游 B、C 的调用都正常，那么“网络问题”的假设就站不住脚了。

#### D. T-1 时序铁律
*   **逻辑:** 原因必须严格早于结果。
*   **验证:** 若系统发现 $T_{cause} > T_{error}$（即所谓的“根因”事件发生时间晚于故障报错时间），该结论将被系统自动标记为“逻辑谬误”并被丢弃，强制 LLM 重新寻找真正的触发点。


---

## 4. 总结：工业级的克制

**AIOps-Intelligent-RCA v2.0** 代表了一种架构上的成熟与克制。

*   我们放弃了让 Agent 像人类一样在终端里敲 `ls` 和 `grep` 的幻想。
*   我们选择了 **RPC Error** 这个单一且覆盖率极高的抓手。
*   我们建立了 **“算法清洗 -> SOP 路由 -> LLM 判决”** 的严密流水线。

这是一个**“SRE 经验代码化”**与**“LLM 语义理解能力”**的完美结合。它也许不再像科幻电影里的 AI 那样“自主”，但它能稳定地、准确地、7x24 小时地守住生产环境的生命线。
*   我们建立了 **“算法清洗 -> SOP 路由 -> LLM 判决”** 的严密流水线。

这是一个**“SRE 经验代码化”**与**“LLM 语义理解能力”**的完美结合。它也许不再像科幻电影里的 AI 那样“自主”，但它能稳定地、准确地、7x24 小时地守住生产环境的生命线。
