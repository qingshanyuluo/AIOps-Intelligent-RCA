# AIOps-Intelligent-RCA v2.0: 神经符号化故障分诊引擎

> **Author:** qingshanyuluo
> **Status:** Production-Grade State of the Art
> **Core Philosophy:** "Deterministic Workflow, Probabilistic Inference" (确定性的流，概率性的脑)
> **Architecture Pattern:** Neuro-Symbolic AI (神经符号人工智能)

---

## 1. 序言：从“黑盒代理”到“白盒工厂”

在经历了 ReAct (Reasoning and Acting) 模式在运维领域的幻觉与不可控后，我们回归了第一性原理：**运维排障的本质不是探索（Exploration），而是验证（Verification）。**

当前市面上的 AIOps 方案依然沉迷于让 LLM 像人一样去使用工具（Tool-use），这忽略了一个致命的事实：**大模型严重缺乏运维领域的“过程思维链”训练数据。**

**本项目的核心破局点在于“去 Agent 化”：**
1.  **收敛入口：** 我们不再监听全网所有指标，而是锁死 **RPC Error** 这一“黄金咽喉”。经验证明，RPC 异常覆盖了 90% 的异常与 100% 的生产故障。
2.  **固化流程：** 放弃不确定的 ReAct 循环，采用 **分支型固定 SOP (Branching Fixed SOP)**。
3.  **LLM 降级：** LLM 不再是指挥官（Commander），而是流水线上的 **高智商质检员 (Node)**。它不负责决定“下一步做什么”，只负责在给定的步骤中“看懂非结构化数据”。

我们构建的不是一个会聊天的机器人，而是一座**由算法驱动传送带、由 LLM 负责精细加工的自动化分诊工厂**。

---

## 2. 核心架构：漏斗式分诊流水线 (The Triage Funnel)

我们将 RCA 过程重构为**高度收敛**的四阶段漏斗。所有故障必须经过这套严格的“安检”，确保每一步的输入都是经过高度结构化处理的。

### Stage 0: 全局嫌疑人识别与证据固定 (The Dossier)
*   **目标：** 在故障发生的瞬间，构建一个包含所有潜在关联方的“案发现场快照”，避免因只关注报错应用而遗漏“沉默的性能恶化者”。
*   **动作：**
    1.  **识别嫌疑人：** 通过监控实时 RPC 错误流和扫描全局服务性能指标，生成一份包含**报错池 (Error Pool)**和**异动池 (Anomaly Pool)**的完整嫌疑人名单。
    2.  **并发固定证据：** 对名单中的所有应用，并发抓取其排障所需的全量数据（指标、日志、告警、变更、线程 Dump 等）。
*   **输出：** 一个标准化的 **“故障档案 (Dossier)”**，作为整个后续分析流程的唯一、不可变的数据源。

### Stage 1: 全局共模熔断 (The Shield)
*   **目标：** 快速识别并熔断由基础设施或平台级故障引发的“告警风暴”，防止系统在无效的单点分析上空耗资源。
*   **动作：** 通过分析全局服务的错误率分布模式，判定故障是“平台型”（影响范围广，错误率分布平缓）还是“断崖型”（集中在少数应用）。
*   **决策：**
    *   **平台型故障：** 直接熔断，输出全局告警（如：网络专线抖动、云厂商故障），终止后续分析。
    *   **断崖型故障：** 将错误率最高的应用视为主要嫌疑人，放行至下一阶段。

### Stage 2: 加权拓扑挖掘与入口纠偏 (The Compass)
*   **目标：** 纠正一个常见的误区——报错节点不等于根因节点。此阶段旨在通过纯数学计算，定位到分布式链路中真正的“阻力点”。
*   **动作：**
    1.  **构建内存拓扑图：** 将批量错误 Trace 在内存中实时折叠成一个局部加权拓扑图。
    2.  **计算破坏力权重：** 对图中的每条“边”和每个“节点”计算其对链路的综合影响权重。
    3.  **强制校准入口：** 根据权重计算结果，**动态纠偏**分析入口，可能指向某个**交互/网络问题（边）**、某个**节点自身计算问题**或保持原有的**报错节点**。
*   **价值：** 此阶段确保了后续所有深度分析都聚焦在经过数据验证的、真正的瓶颈之上。

### Stage 3: 证据深化与现场重建 (The Investigator)
*   **目标：** 围绕 Stage 2 确定的核心嫌疑对象，进行多维度的深度证据勘探，并构建一张完整的“故障全景图”。
*   **动作：**
    1.  **日志趋势突变检测：** 自动发现异常激增的错误日志模式。
    2.  **核心指标语义化：** 将原始指标（如 `cpu_steal > 0.5`）翻译成 SRE 能理解的结构化事件（`{event: "CPU被云厂商抢占", level: "critical"}`）。
    3.  **变更信息精简：** 过滤并关联出小范围内、高相关的变更嫌疑列表。
    4.  **递归式现场扩展：** 检查核心嫌疑人的高流量下游，若其自身也存在性能异常，则递归地将其纳入“案发现场”，并采集其全套证据。
*   **输出：** 一张包含所有被证实存在异常的节点的 **“故障全景图 (Incident Panorama)”**。

### Stage 4: 两阶段交叉审问与定责 (The Prosecutor)
*   **目标：** 克服大模型在处理复杂信息时的“惰性”和“逻辑谬误”，通过结构化的质询流程，逼近故障真相。
*   **动作：**
    1.  **Phase 1 - 强制循证与浅层结论提取：** 通过引导式 Prompt，强制 LLM 完整消化所有证据材料，并提炼出一个初步的、未经审视的故障猜想。
    2.  **Phase 2 - 反事实质询与深度归因：** 系统自动生成一系列基于 SRE 第一性原理的“反事实”问题，挑战并质疑第一阶段的浅层结论。LLM 必须在逻辑压力下捍卫、修正或推翻其初步判断。
*   **最终输出：** 一份经过交叉审问和逻辑验证的、高置信度的最终诊断报告。

---

## 3. 核心算法与原则

本项目的有效性根植于一系列为运维场景深度定制的算法和逻辑原则。

### 3.1 嫌疑人识别与故障定界算法
*   **带噪底的自适应 Z-Score (Adaptive Z-Score with Noise Floor):** 用于 Stage 0。此算法在传统 Z-Score 基础上增加了对稳定“噪声”的识别，能精准识别出那些“行为反常”（如耗时显著偏离自身历史基线）的服务，即使它们尚未报错。
*   **基于“错误率梯度”的故障定界算法 (Error Rate Gradient-based Fault Localization):** 用于 Stage 1。通过计算和比较归一化后服务错误率的**梯度（倍数差）**，快速区分是影响面广的“平台型”故障（梯度平缓），还是由单点爆发的“断崖型”故障（梯度陡峭）。

### 3.2 拓扑瓶颈定位算法
*   **基于 Trace 聚合的加权拓扑挖掘 (Trace-Aggregated Weighted Mining):** 用于 Stage 2 的核心。它通过一个统一的“阻力”公式，量化分布式调用链路中每个环节的破坏力。

    $$W_{edge} = \underbrace{(AvgLat \times SpanCount)}_{\text{交互耗时 (含N+1)}} + \underbrace{\sum(ClientDur - ServerDur)}_{\text{网络/GC等传输损耗}} + \underbrace{(ErrorCount \times K)}_{\text{稳定性惩罚}}$$
    
    该算法无需外部图数据库，直接在内存中将批量 Trace **折叠 (Folding)** 成加权图，动态找出链路中的“最大阻力点”。

### 3.3 自动化反事实验证逻辑
这是 Stage 4 中用于挑战 LLM 初步结论的“质询生成器”，其核心是编码化的 SRE 经验。
*   **概率独立性原则 (针对超时场景):**
    *   **现象:** MySQL, Redis, ES 等多个独立组件同时变慢。
    *   **反事实质询:** “三个独立组件同时发生物理故障的概率趋近于零。请解释为何不是调用方自身（如 GC 停顿或 CPU 争抢）导致了计时器异常？”
    *   **口诀:** **单独涨 = 组件问题；一起涨 = 自身问题。**
*   **资源受害者假设 (针对资源报警):**
    *   **现象:** 应用 CPU 100%。
    *   **反事实质询:** “请计算 `Impact = ΔLatency × QPS`。如果 CPU 飙升并未导致服务质量（QPS、延迟）出现显著恶化，请论证它为何是‘原因’而非‘结果’（例如，由下游变慢导致线程池堆积所引发）？”
*   **T-1 时序铁律:**
    *   **逻辑:** 原因必须早于结果。
    *   **验证:** 系统会自动检查结论中的因果时序。若 $T_{cause} > T_{error}$，该结论将被自动标记为“逻辑谬误”并要求 LLM 重新评估。

---

## 4. 总结：工业级的克制

**AIOps-Intelligent-RCA v2.0** 代表了一种架构上的成熟与克制。

*   我们放弃了让 Agent 像人类一样在终端里敲 `ls` 和 `grep` 的幻想。
*   我们选择了 **RPC Error** 这个单一且覆盖率极高的抓手。
*   我们建立了 **“算法清洗 -> SOP 路由 -> LLM 判决”** 的严密流水线。

这是一个**“SRE 经验代码化”**与**“LLM 语义理解能力”**的完美结合。它也许不再像科幻电影里的 AI 那样“自主”，但它能稳定地、准确地、7x24 小时地守住生产环境的生命线。
*   我们建立了 **“算法清洗 -> SOP 路由 -> LLM 判决”** 的严密流水线。

这是一个**“SRE 经验代码化”**与**“LLM 语义理解能力”**的完美结合。它也许不再像科幻电影里的 AI 那样“自主”，但它能稳定地、准确地、7x24 小时地守住生产环境的生命线。
