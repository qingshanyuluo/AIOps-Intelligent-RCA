# 幻觉与现实：从 ReAct 智能体到确定性工作流 —— 我在 AIOps 根因定位中的“祛魅”之旅

> ​**摘要**​：本文复盘了一次尝试构建“运维版 Cursor”的失败经历。实验证明，即便通过预处理提供了高密度的运维数据，ReAct 模式依然无法带来正向收益。基于第一性原理，本文揭示了其根本原因不在于 prompt 或数据清洗，而在于​**大模型训练集在“运维排障轨迹”上的巨大空缺**​。因此，AIOps 的正确架构应当是：LLM 不做自主决策的驾驶员，只做固定 SOP 流程中的高智商节点。

---

## 引言：寻找运维领域的 "Cursor"

在大模型爆发的初期，我和许多开发者一样，怀揣着一个性感的构想：**能不能利用 ReAct（Reasoning and Acting）模式，打造一个运维领域的 Autonomous Agent？**

我的愿景很清晰：构建一个类似 Cursor 的智能助手，赋予它查询日志、调取监控指标（Metrics）、读取元数据（Metadata）的工具。期望它能像一位经验丰富的 SRE，面对报警，自主思考，自主调用工具，层层下钻，最终定位根因。

然而，这场从理想通往现实的实验，最终迫使我重写了整个系统架构。

## 一、 实验与困境：被“硬编码”的智能

在第一阶段，我投入了大量精力设计 Tool use 和优化 Prompt。但在实际运行中，ReAct 模式的效果令人失望。

我一度认为问题出在输入数据的质量上。于是，我通过精心的数据工程，将原始低密度的日志转化为**高密度、高逻辑自洽的聚合数据**喂给 LLM。我原本期望，数据质量的提升能激活 LLM 的推理能力，让它像分析代码一样分析运维数据。

但实验结果给了我当头一棒：

即便面对高质量的数据，Agent 依然无法展现出超越原有 SOP（标准作业程序）的能力。在面对特殊案例时，我不得不反复调试 Prompt，甚至把排障步骤隐式地写死在 Prompt 里才勉强跑通。
最终我发现：**这不就是用自然语言把固定代码重写了一遍吗？** 这种 Agent 不仅没有带来比固定流程更高的收益，反而引入了极大的不确定性和耗时。

### ...（接第一章：被“硬编码”的智能）

为了让大家直观感受这种“伪智能”的荒谬，我展示一段我为了解决“因果倒置”幻觉而不得不写死的 Prompt。

在排障中，LLM 经常犯一个低级错误：把结果当成原因。例如，因为它看到数据库报错在先，就认为是数据库挂了，完全忽略了服务在 5 分钟前就已经 OOM（内存溢出）导致了连接中断。

为了纠正这个逻辑，我不得不把 SRE 的大脑皮层“翻译”成如下的文字：

#### 案例展示：一段被迫“手把手教学”的 Prompt

> **🕵️ Step 4: 因果倒置时序验证（避免"症状被误判为根因"）**
>
> **你必须强制执行以下【三步验证法】：**
>
> **验证 4.1: T-1 精确时序判定**
> *   **逻辑核心**：原因 (Cause) 必须在时间轴上严格早于或同时于 结果 (Effect)。
> *   **验证规则**：如果 `T_cause > T_error`：**你的结论绝对是错的**。后果不可能发生在原因之前，必须推翻！
>
> **验证 4.2: "资源即受害者"假设**
> *   **场景**：如果多个组件（MySQL + Redis + ES）耗时同时上涨 + GC/CPU 异常。
> *   **反事实推理**：现实中，所有组件服务端**几乎不可能同时**出问题。
> *   **结论**：99% 的概率是服务自身 GC/CPU 问题导致的，组件耗时是“被动上涨”。
>
> **验证 4.3: 排除"幸存者偏差"**
> *   **执行检查**：如果认为是网络抖动，检查同网段的其他服务为什么没报错？
> ... （此处省略数百字细节指令）

#### 看到这里，你发现问题了吗？

写完这段 Prompt 的那一刻，我突然意识到我在做一件极其低效的事情：

1.  **我在教 AI 做小学数学题：** `if T_cause > T_error then False`。这在 Python 里只是一行代码，而在 Prompt 里我需要用几百个 Token 去“恳求”大模型不要产生幻觉。
2.  **我在教 AI 做条件判断：** “如果 CPU 高且依赖慢，则是 CPU 问题”。这本质上是一个确定性的**决策树（Decision Tree）**。
3.  **算力错配：** 我动用了几千张 H100 的算力，去执行一段本该由 `if-else` 逻辑完成的确定性校验。

**这根本不是 AI 在思考，这是我在用自然语言写汇编语言。**

既然这些步骤（时序校验、资源排查、幸存者偏差）是如此固定且必须执行的，**为什么不直接写成 Workflow 代码，而要期待 LLM “灵光一现”去自主想到它？**

LLM 根本不可能“自主”想到去对比 `T_cause` 和 `T_error`，除非它的训练数据里包含大量 SRE 拿着放大镜比对时间戳的“思维轨迹”——而正如前文所说，这些数据在大模型的世界里是真空的。

这也直接引出了我对 AIOps 架构的终极反思。


## 二、 第一性原理反思：为什么“高质量数据”救不了 ReAct？

为什么代码场景（Cursor/Copilot）能成，而运维场景即便清洗了数据也跑不通？经过深度调研和反思，我找到了导致失败的​**终极变量**​。

### 1. 训练集的本质性缺失：不仅仅是数据，是“轨迹”

我们往往认为运维难是因为数据脏（日志是非结构化的）。但我的实验证明，即使把数据洗干净了，LLM 依然不懂怎么排障。

**核心原因在于：大模型厂商（OpenAI/Anthropic）手里根本没有运维场景的“思维链数据集”。**

* **代码世界（Github）：** 拥有万亿级的 Token。更重要的是，Github 上的 Issue 讨论、Pull Request 的修改记录、StackOverflow 的问答，构成了完整的 **Problem \$\\to\$ Context \$\\to\$ Reasoning \$\\to\$ Fix** 的闭环。LLM 见过无数次“错误是如何被纠正的”。
* **运维世界（黑盒）：** 极度封闭。
  * **没有哪家互联网大厂会把自己生产环境的故障排查全过程（Context + Action + Result）开源出来。**
  * 这些包含着 SRE 宝贵经验的“排障思维链”和“操作轨迹”，全部躺在公司内部的保密文档或工程师的大脑里，从未进入过 GPT 的预训练语料库。

### 2. 只有“状态”，没有“逻辑”

因此，目前的 LLM 在运维领域是“先天营养不良”的。它可能见过 Linux 手册（静态知识），但从未见过真实的、复杂的排障动态过程（过程知识）。

这就是为什么即便我喂给它高密度的数据，它依然只能做简单的模式匹配，而无法像真正的 SRE 那样进行复杂的假设验证和逻辑推演。它的“智商”上限，已经被训练数据锁死在了通用常识水平，远低于企业内部沉淀多年的 SOP。

## 三、 特例辨析：K8s Native Agent 为什么能成？

调研中，我发现市场上唯一的“成功者”是类似 K8sGPT、HolmesGPT 这类产品。这似乎反驳了我的观点？

**不，这恰恰验证了我的观点。**

K8s Agent 的成功建立在 Kubernetes 极度标准化的世界观之上：

* Pod 就是 Pod，Service 就是 Service。
* 状态机是有限且封闭的（Pending, Running, CrashLoopBackOff）。

K8s Agent 并不需要“探索”，它利用的是 K8s 的​**声明式 API（Declarative API）**​。它在遍历一个标准的、确定性的状态树，而不是在未知的丛林中探险。这就好比查字典，而非破案。这是一种\*\*“伪自主”\*\*。

一旦问题溢出 K8s 层级（例如业务代码逻辑死锁，但 Pod 状态依然是 Running），这些 Agent 瞬间就会失效。

## 四、 最终架构：LLM as a Node，Not the Brain

基于以上推导，我得出了 AIOps 落地的最终结论：

**放弃“全自动驾驶”，拥抱“辅助驾驶”。**

既然 LLM 缺乏排障的“过程记忆”，我们就不能指望它掌控工作流（Workflow）。它不应该是指挥官，而应该是流水线上的特定​**功能节点**​。

**新的范式如下：**

1. **控制权回归代码：** 使用 Python 或工作流引擎（Workflow Engine）固化 SOP。排查流程的主干必须是企业内部沉淀下来的、确定性的专家经验。
2. **LLM 的正确生态位：** 在这个固定的流程中，利用 LLM 的通用泛化能力：
   * **思维链（Chain of Thought）：** 在流程的特定卡点，让 LLM 基于上下文提出假设（“基于这些指标，列出 3 个可能的根因”），再由固定脚本去验证。
   * **非结构化转结构化：** 从杂乱的日志中提取实体。
   * **逻辑反驳（Critic）：** “如果结论是 A，但现象包含 B，这是否矛盾？”

我们不再强求 LLM 像人一样去“操作”系统，而是让 LLM 为确定性的脚本提供“思考力”和“联想力”。

## 结语

通往 AIOps 的道路，不是依靠 Prompt 堆砌出来的“魔法”，而是对数据本质的深刻理解。

承认 LLM 在运维领域的\*\*“训练数据真空”\*\*，是走向成熟的第一步。在某一天大厂们愿意开源其内部的 Incident Post-mortem 数据库之前，**SOP + LLM Node** 才是当下最稳健、最高效的解法。
